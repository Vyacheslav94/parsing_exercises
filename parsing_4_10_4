import requests
from bs4 import BeautifulSoup
import json

result_json = []
with open('mouse.json', 'w', encoding='utf-8') as file:               # создаем файл
    (file)
# 1 ----------------
for page in range(1, 5):                                            # пробегаем циклом по всем страницам в разделе мыши
    url = f'http://parsinger.ru/html/index3_page_{page}.html'
    response = requests.get(url=url)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'lxml')
# 1 ----------------
# 2 ----------------  парсинг
    name = [x.text.strip() for x in soup.find_all('a', class_='name_item')] # вытаскиваю Наименование
    description = [x.text.strip().split('\n') for x in soup.find_all('div', class_='description')]
    price = [x.text for x in soup.find_all('p', class_='price')]

# 2 ----------------  парсинг
    for list_item, price_item, name in zip(description, price, name): # пробегаем циклом по всем страницам в разделе мыши
        result_json.append({
            'name': name,
            'brand': [x.split(':')[1] for x in list_item][0],
            'type': [x.split(':')[1] for x in list_item][1],
            'connect': [x.split(':')[1] for x in list_item][2],
            'game': [x.split(':')[1] for x in list_item][3],
            'price': price_item
        })

with open('mouse.json', 'a', encoding='utf-8') as file:               # добавляем данные со всех страниц
    json.dump(result_json, file, indent=4, ensure_ascii=False)
print("Done")
